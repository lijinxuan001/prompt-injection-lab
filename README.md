
# ðŸ§  Prompt Injection Lab

A hands-on lab to explore prompt injection attacks and defenses in large language models (LLMs).  
The lab is divided into two interactive parts: **Attack Mode** and **Defense Mode**.

---

## ðŸŽ¯ Modes

### Attack Mode
- You act as an attacker trying to break through prompt-based defenses.
- Each level increases in difficulty with stronger model protections.
  - level 1: Zero Protection
  - level 2: Input filtering
  - level 3: Output filtering
  - level 4: Input filtering & Output filtering 
  - level 5: LLM-based Injection Detection

### Defense Mode
- You act as the LLM system designer.
- Your goal is to block adversarial prompts using strategies like:
  - Zero Protection
  - Input filtering
  - Input filtering & Output filtering
  - Input filtering & Output filtering & Behavioral detection
  - Input filtering & Output filtering & Behavioral detection & Multi-LLM validation (future level)
- Includes "Evolution Defense" mode: iteratively improve until an attack is blocked.

---

## ðŸš€ Getting Started

1. Make sure [Ollama](https://ollama.com) is installed and a model is running, e.g.:
```bash
ollama run llama3
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Run the lab:
```bash
python main.py
```

4. quit the lab:
```bash
Your attack prompt: /quit
```

5. guess the result :
```bash
Your attack prompt: /guess
```
---

## ðŸ“‚ Project Structure

```
prompt-injection-lab-final/
â”œâ”€â”€ attacker_mode/        # Attack side logic & levels
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ playdirect.py
â”‚   â”œâ”€â”€ playindirect.py
â”‚   â””â”€â”€ levels/
â”‚       â”œâ”€â”€ level_*.json
â”‚       â””â”€â”€ secret.json
â”œâ”€â”€ defender_mode/        # Defense side logic & scenarios
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ evolve.py
â”‚   â”œâ”€â”€ indirect.py
â”‚   â”œâ”€â”€ files/
â”‚   â””â”€â”€ scenarios/
â”‚       â””â”€â”€ scenario_1.json
â”œâ”€â”€ engine/               # Shared model & scoring engine
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ llm.py
â”‚   â”œâ”€â”€ password.py
â”‚   â”œâ”€â”€ llmdetector.py
â”‚   â”œâ”€â”€ scored.py
â”‚   â””â”€â”€ runner.py
â”œâ”€â”€ main.py               # Entry point
â””â”€â”€ requirements.txt      # Dependencies
```
